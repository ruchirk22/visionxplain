# VisionXplain: Explainable AI for Image Descriptions

## Overview

**VisionXplain** is an open-source prototype that generates explainable and traceable image descriptions using a multimodal pipeline. It combines computer vision (CV) to "see" objects in an image and natural language processing (NLP) to describe them, with a key focus on explainability.

Problem Addressed: [Challenges Attached to Generative AI](https://www.hcltech.com/trends-and-insights/challenges-attached-generative-ai)

This project directly addresses the challenge of "Explainability and Traceability" in generative AI, where opaque model decisions can hinder reliability. For any image processed, VisionXplain can produce:

- A textual description.
- A visual "saliency map" highlighting which pixels influenced the model's predictions.
- A complete audit log tracing the process from input to output.  
- Built for efficiency, and it uses lightweight, pre-trained PyTorch models.
- This project showcases PyTorch, CV, NLP, and model interpretability.

## Features

- **Data Ingestion**: Downloads and preprocesses a 100-image subset of the MS-COCO dataset, creating an initial traceability log.
- **CV Module**: Uses a pre-trained MobileNetV2 to detect objects in images and logs the predictions with confidence scores.
- **NLP Module**: Uses the detected objects to create a prompt for a pre-trained DistilGPT-2 model, which generates a descriptive caption.
- **Explainability Module**: Produces visual saliency maps using Captum's Integrated Gradients to show which image regions were most important for the CV model's top prediction.
- **Traceability Module**: Consolidates all individual logs into a single master\_traceability\_log.json file for complete, end-to-end auditing.
- **User Interface**: A user-friendly web app built with Streamlit that includes:
  - An evaluation dashboard with key project metrics.
  - An interactive explorer to view images, descriptions, explanations, and logs.

## Project Structure

```bash
visionxplain/
├── src/
│   ├── app.py                     # Main Streamlit web application
│   ├── data_ingestion.py          # Feature 1: Handles data download & prep
│   ├── cv_module.py               # Feature 2: Object detection
│   ├── nlp_module.py              # Feature 3: Text generation
│   ├── explainability_module.py   # Feature 4: Saliency map generation
│   └── traceability_module.py     # Feature 5: Master log consolidation
├── data/                          # (Generated by scripts) Logs & explanations
│   ├── val2017/                   # Downloaded images
│   ├── annotations/               # Downloaded annotation files
│   ├── explanations/              # Saved saliency maps
│   ├── traceability_log.json
│   ├── cv_module_log.json
│   ├── nlp_module_log.json
│   └── master_traceability_log.json
└── requirements.txt               # Project dependencies
```

## Installation

### Prerequisites

- macOS with Apple Silicon (M1/M2/M3) recommended
- Python 3.10+
- Git

### Steps

```bash
# 1. Clone the repository
git clone https://github.com/ruchirk22/visionxplain.git
cd visionxplain

# 2. Create and activate a virtual environment
python3 -m venv .venv
source .venv/bin/activate

# 3. Install dependencies
pip install -r requirements.txt
```

## Usage

The project is run feature-by-feature to generate the necessary data and logs, culminating in the web application.

- Run the Pipeline Scripts in Order (Execute each script from the root `visionxplain/` directory):

```bash
# 1. Download data and create the first log
python src/data_ingestion.py

# 2. Process images and create the CV log
python src/cv_module.py

# 3. Generate descriptions and create the NLP log
python src/nlp_module.py

# 4. Generate a sample explanation map
python src/explainability_module.py

# 5. Consolidate all logs into the master log
python src/traceability_module.py
```

- Run the Streamlit Web App:

```bash
streamlit run src/app.py
```

- Access the UI in your browser (usually at [http://localhost:8501](http://localhost:8501)) to view the dashboard and explore the results.

## Acknowledgments

- Inspired by HCL Technologies' insights on generative AI challenges.
- Built with the incredible open-source libraries: PyTorch, Hugging Face Transformers, Captum, and Streamlit.
- For any issues with this repository, kindly contact [ruchirkulkarni22@gmail.com](mailto:ruchirkulkarni22@gmail.com)
